{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accident Severity Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/us-accidents/US_Accidents_June20.csv\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        filepath = os.path.join(dirname, filename)\n",
    "        print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Source', 'TMC', 'Severity', 'Start_Time', 'End_Time',\n",
       "       'Start_Lat', 'Start_Lng', 'End_Lat', 'End_Lng', 'Distance(mi)',\n",
       "       'Description', 'Number', 'Street', 'Side', 'City', 'County', 'State',\n",
       "       'Zipcode', 'Country', 'Timezone', 'Airport_Code', 'Weather_Timestamp',\n",
       "       'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)',\n",
       "       'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)',\n",
       "       'Precipitation(in)', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing',\n",
       "       'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station',\n",
       "       'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop',\n",
       "       'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight',\n",
       "       'Astronomical_Twilight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(filepath)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['Severity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_datetime(x):\n",
    "    x = datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "    return x\n",
    "\n",
    "def get_acc_len(x):\n",
    "    x = x.total_seconds() / 60.0\n",
    "    return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.42255624332331\n",
      "170.6\n",
      "-500.0\n",
      "63.624498059976375\n",
      "100.0\n",
      "-10.0\n",
      "-5.759011884333611\n",
      "25.0\n",
      "-10.0\n",
      "-240.77838879416709\n",
      "115.0\n",
      "-500.0\n",
      "21.319353845340995\n",
      "57.74\n",
      "-500.0\n",
      "-1.8688801995208821\n",
      "140.0\n",
      "-500.0\n"
     ]
    }
   ],
   "source": [
    "##### Feature extraction and clean-up ######\n",
    "\n",
    "#start time, end time --> length of accident\n",
    "end_time = data['End_Time'].apply(str_to_datetime)\n",
    "start_time = data['Start_Time'].apply(str_to_datetime)\n",
    "data['Accident_Length'] = end_time - start_time \n",
    "X['Accident_Length'] = data['Accident_Length'].apply(get_acc_len)\n",
    "X['Accident_Length']\n",
    "\n",
    "\n",
    "X['Accident_Distance'] = data['Distance(mi)']\n",
    "X['Accident_Distance'].fillna(-500.0, inplace = True) \n",
    "\n",
    "X['Temp'] = data['Temperature(F)']\n",
    "X['Temp'].fillna(-500.0, inplace = True) \n",
    "X['Temp']\n",
    "\n",
    "print(X['Temp'].mean())\n",
    "print(X['Temp'].max())\n",
    "print(X['Temp'].min())\n",
    "\n",
    "X['Humidity'] = data['Humidity(%)']\n",
    "X['Humidity'].fillna(-10.0, inplace = True) \n",
    "X['Humidity']\n",
    "\n",
    "print(X['Humidity'].mean())\n",
    "print(X['Humidity'].max())\n",
    "print(X['Humidity'].min())\n",
    "\n",
    "X['Precipitation'] = data['Precipitation(in)']\n",
    "X['Precipitation'].fillna(-10.0, inplace = True) \n",
    "X['Precipitation']\n",
    "\n",
    "print(X['Precipitation'].mean())\n",
    "print(X['Precipitation'].max())\n",
    "print(X['Precipitation'].min())\n",
    "\n",
    "X['Wind_Chill'] = data['Wind_Chill(F)']\n",
    "X['Wind_Chill'].fillna(-500.0, inplace = True) \n",
    "X['Wind_Chill']\n",
    "\n",
    "print(X['Wind_Chill'].mean())\n",
    "print(X['Wind_Chill'].max())\n",
    "print(X['Wind_Chill'].min())\n",
    "\n",
    "X['Pressure'] = data['Pressure(in)']\n",
    "X['Pressure'].fillna(-500.0, inplace = True) \n",
    "X['Pressure']\n",
    "\n",
    "print(X['Pressure'].mean())\n",
    "print(X['Pressure'].max())\n",
    "print(X['Pressure'].min())\n",
    "\n",
    "X['Visibility'] = data['Visibility(mi)']\n",
    "X['Visibility'].fillna(-500.0, inplace = True) \n",
    "X['Visibility']\n",
    "\n",
    "print(X['Visibility'].mean())\n",
    "print(X['Visibility'].max())\n",
    "print(X['Visibility'].min())\n",
    "\n",
    "X['Severity'] = data['Severity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accident_Length      False\n",
       "Accident_Distance    False\n",
       "Temp                 False\n",
       "Humidity             False\n",
       "Precipitation        False\n",
       "Wind_Chill           False\n",
       "Pressure             False\n",
       "Visibility           False\n",
       "Severity             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 29174, 2: 2373210, 3: 998913, 4: 112320}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(X['Severity'].values, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3372123, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "X = X[X['Severity'] < 4] \n",
    "X = X[X['Severity'] > 1]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 2373210, 3: 998913}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(X['Severity'].values, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.20822665e-04,  2.99733233e-05,  7.38000000e-02, ...,\n",
       "        -1.00000000e+00,  5.93600000e-02,  2.00000000e-02],\n",
       "       [ 2.10977069e-05,  2.99733233e-05,  7.58000000e-02, ...,\n",
       "        -1.00000000e+00,  5.93000000e-02,  2.00000000e-02],\n",
       "       [ 2.10977069e-05,  2.99733233e-05,  7.20000000e-02, ...,\n",
       "         6.66000000e-02,  5.93400000e-02,  2.00000000e-02],\n",
       "       ...,\n",
       "       [ 2.00193797e-05,  1.68150344e-03,  1.46000000e-01, ...,\n",
       "         1.46000000e-01,  5.94800000e-02,  2.00000000e-02],\n",
       "       [ 2.06405899e-05,  2.31394056e-03,  1.42000000e-01, ...,\n",
       "         1.42000000e-01,  5.92400000e-02,  2.00000000e-02],\n",
       "       [ 2.06874737e-05,  1.60956746e-03,  1.58000000e-01, ...,\n",
       "         1.58000000e-01,  5.72600000e-02,  1.40000000e-02]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Normalization #####\n",
    "transformer = MaxAbsScaler().fit(X.iloc[:,:8].values)\n",
    "X_norm = transformer.transform(X.iloc[:,:8])\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3372123, 8)\n",
      "(3372123, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.20822665e-04, 2.99733233e-05, 7.38000000e-02, ...,\n",
       "        5.93600000e-02, 2.00000000e-02, 3.00000000e+00],\n",
       "       [2.10977069e-05, 2.99733233e-05, 7.58000000e-02, ...,\n",
       "        5.93000000e-02, 2.00000000e-02, 2.00000000e+00],\n",
       "       [2.10977069e-05, 2.99733233e-05, 7.20000000e-02, ...,\n",
       "        5.93400000e-02, 2.00000000e-02, 2.00000000e+00],\n",
       "       ...,\n",
       "       [2.00193797e-05, 1.68150344e-03, 1.46000000e-01, ...,\n",
       "        5.94800000e-02, 2.00000000e-02, 2.00000000e+00],\n",
       "       [2.06405899e-05, 2.31394056e-03, 1.42000000e-01, ...,\n",
       "        5.92400000e-02, 2.00000000e-02, 2.00000000e+00],\n",
       "       [2.06874737e-05, 1.60956746e-03, 1.58000000e-01, ...,\n",
       "        5.72600000e-02, 1.40000000e-02, 2.00000000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_norm.shape)\n",
    "print(X['Severity'].values.reshape(len(X['Severity']),1).shape)\n",
    "np.concatenate((X_norm, X['Severity'].values.reshape(len(X['Severity']),1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x values normalized --> X_norm\n",
    "#y values --> X['Severity']\n",
    "import pandas as pd\n",
    "all_data = pd.DataFrame(np.concatenate((X_norm, X['Severity'].values.reshape(len(X['Severity']),1)), axis=1), columns = X.columns)\n",
    "#all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accident_Length</th>\n",
       "      <th>Accident_Distance</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Wind_Chill</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2499490</th>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.1648</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.06000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959224</th>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.05986</td>\n",
       "      <td>0.020</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256157</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.06014</td>\n",
       "      <td>0.020</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535523</th>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.06002</td>\n",
       "      <td>0.020</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124945</th>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.06030</td>\n",
       "      <td>0.020</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466524</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1518</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.06002</td>\n",
       "      <td>0.020</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714128</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.06004</td>\n",
       "      <td>0.020</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869025</th>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.05900</td>\n",
       "      <td>0.020</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829492</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.05956</td>\n",
       "      <td>0.016</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383553</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1298</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.06050</td>\n",
       "      <td>0.020</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3372123 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Accident_Length  Accident_Distance    Temp  Humidity  Precipitation  \\\n",
       "2499490         0.000253            0.00018  0.1648      0.84           -0.4   \n",
       "959224          0.000065            0.00000  0.1920      0.44            0.0   \n",
       "2256157         0.000021            0.00000  0.1202      0.62           -0.4   \n",
       "1535523         0.000031            0.00000  0.1202      0.80           -0.4   \n",
       "2124945         0.000031            0.00000  0.1540      0.17           -0.4   \n",
       "...                  ...                ...     ...       ...            ...   \n",
       "466524          0.000033            0.00000  0.1518      1.00           -0.4   \n",
       "1714128         0.000021            0.00000  0.1422      0.90           -0.4   \n",
       "869025          0.000042            0.00000  0.0580      0.67            0.0   \n",
       "1829492         0.000021            0.00000  0.1580      0.77            0.0   \n",
       "1383553         0.000021            0.00000  0.1298      0.90           -0.4   \n",
       "\n",
       "         Wind_Chill  Pressure  Visibility  Severity  \n",
       "2499490      -1.000   0.06000       0.010       2.0  \n",
       "959224       -1.000   0.05986       0.020       2.0  \n",
       "2256157      -1.000   0.06014       0.020       2.0  \n",
       "1535523      -1.000   0.06002       0.020       2.0  \n",
       "2124945      -1.000   0.06030       0.020       3.0  \n",
       "...             ...       ...         ...       ...  \n",
       "466524       -1.000   0.06002       0.020       2.0  \n",
       "1714128      -1.000   0.06004       0.020       2.0  \n",
       "869025        0.044   0.05900       0.020       3.0  \n",
       "1829492      -1.000   0.05956       0.016       2.0  \n",
       "1383553      -1.000   0.06050       0.020       2.0  \n",
       "\n",
       "[3372123 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###shuffle data###\n",
    "all_data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3372123\n",
      "3372123\n",
      "3034910\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "print(len(all_data))\n",
    "print(len(all_data))\n",
    "train_frac = int(len(all_data) * 0.9)\n",
    "print(train_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, x, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.x = x\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        #ID = self.x[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        \n",
    "        curr_x = self.x[index]\n",
    "\n",
    "        y = self.labels[index]\n",
    "        out_y = np.zeros(2)\n",
    "        out_y[int(y)] = 1    \n",
    "\n",
    "        return curr_x, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataloader ###\n",
    "training_set = Dataset(all_data.iloc[:train_frac,:8].values, all_data.iloc[:train_frac, 8].values - 2)\n",
    "training_generator = data.DataLoader(training_set, batch_size=20000, shuffle=True)\n",
    "\n",
    "test_set = Dataset(all_data.iloc[train_frac:,:8].values, all_data.iloc[train_frac:, 8].values - 2)\n",
    "test_generator = data.DataLoader(test_set, batch_size=len(all_data[train_frac:]), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Accident_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Accident_Model, self).__init__()\n",
    "        self.w1 = nn.Linear(8,8,bias=True)\n",
    "        nn.init.xavier_uniform_(self.w1.weight)\n",
    "        nn.init.zeros_(self.w1.bias)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(8)\n",
    "        \n",
    "        \n",
    "        self.w2 = nn.Linear(8,4,bias=True)\n",
    "        nn.init.xavier_uniform_(self.w2.weight)\n",
    "        nn.init.zeros_(self.w2.bias)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(4)\n",
    "        \n",
    "        \n",
    "        self.w3 = nn.Linear(4,2,bias=True)\n",
    "        nn.init.xavier_uniform_(self.w3.weight)\n",
    "        nn.init.zeros_(self.w3.bias)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(x)\n",
    "        x = x.float()\n",
    "        x = self.bn1(F.relu(self.w1(x)))\n",
    "        #x = self.w2(x)\n",
    "        \n",
    "        x = self.bn2(F.relu(self.w2(x)))\n",
    "        x = self.w3(x)\n",
    "        x_layer_pred.append(x)\n",
    "        '''\n",
    "        x = self.w1(x.float())\n",
    "        x = F.relu(self.w1(x.float()))\n",
    "        x = self.w2(x)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class_weights = np.asarray([0.8,1.2])\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.divide(1.0, np.add(1.0, np.exp(-1.0*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "Train Loss:  0.8205369296149365\n",
      "Test Loss:  0.8243731295144832\n",
      "[[7832 3121]\n",
      " [5994 3053]]\n",
      "(array([0.71505524, 0.33745993]), array([0.56646897, 0.49449304]), array([0.63214819, 0.4011563 ]), array([13826,  6174]))\n",
      "\n",
      "\n",
      "[[148444  34286]\n",
      " [120399  34084]]\n",
      "(array([0.81236797, 0.22063269]), array([0.55215869, 0.49852274]), array([0.65745295, 0.30588774]), array([268843,  68370]))\n",
      "Accuracy Train:  0.54425\n",
      "Accuracy Test:  0.5412839955754968\n",
      "Step: 0\n",
      "Train Loss:  0.7973486997977018\n",
      "Test Loss:  0.7976784298342782\n",
      "[[8445 3507]\n",
      " [5339 2709]]\n",
      "(array([0.70657631, 0.33660537]), array([0.61266686, 0.43581081]), array([0.65627914, 0.37983735]), array([13784,  6216]))\n",
      "\n",
      "\n",
      "[[160799  37539]\n",
      " [108044  30831]]\n",
      "(array([0.81073218, 0.2220054 ]), array([0.59811488, 0.4509434 ]), array([0.68837988, 0.29753191]), array([268843,  68370]))\n",
      "Accuracy Train:  0.5577\n",
      "Accuracy Test:  0.5682758375270229\n",
      "Step: 1\n",
      "Train Loss:  0.7904413044520825\n",
      "Test Loss:  0.7871426690583545\n",
      "[[8628 3560]\n",
      " [5188 2624]]\n",
      "(array([0.70790942, 0.3358935 ]), array([0.62449334, 0.42432083]), array([0.66359022, 0.37496428]), array([13816,  6184]))\n",
      "\n",
      "\n",
      "[[163633  38273]\n",
      " [105210  30097]]\n",
      "(array([0.81044149, 0.22243491]), array([0.60865635, 0.44020769]), array([0.69520275, 0.29553656]), array([268843,  68370]))\n",
      "Accuracy Train:  0.5626\n",
      "Accuracy Test:  0.5745033554459644\n",
      "Step: 1\n",
      "Train Loss:  0.7766689403598713\n",
      "Test Loss:  0.7718885772108414\n",
      "[[8730 3595]\n",
      " [5161 2514]]\n",
      "(array([0.70831643, 0.327557  ]), array([0.62846447, 0.41152398]), array([0.66600549, 0.36477075]), array([13891,  6109]))\n",
      "\n",
      "\n",
      "[[166146  39023]\n",
      " [102697  29347]]\n",
      "(array([0.8098007 , 0.22225167]), array([0.61800382, 0.42923797]), array([0.70102023, 0.29286377]), array([268843,  68370]))\n",
      "Accuracy Train:  0.5622\n",
      "Accuracy Test:  0.579731505013152\n",
      "Step: 2\n",
      "Train Loss:  0.7718691703060072\n",
      "Test Loss:  0.7650726663716443\n",
      "[[8807 3618]\n",
      " [5117 2458]]\n",
      "(array([0.70881288, 0.32448845]), array([0.63250503, 0.40454246]), array([0.66848837, 0.36012014]), array([13924,  6076]))\n",
      "\n",
      "\n",
      "[[167539  39433]\n",
      " [101304  28937]]\n",
      "(array([0.80947664, 0.22218042]), array([0.62318528, 0.42324119]), array([0.70421908, 0.29139373]), array([268843,  68370]))\n",
      "Accuracy Train:  0.56325\n",
      "Accuracy Test:  0.5826465764961611\n",
      "Step: 2\n",
      "Train Loss:  0.7589962151114035\n",
      "Test Loss:  0.7532985655830231\n",
      "[[8933 3695]\n",
      " [4871 2501]]\n",
      "(array([0.70739626, 0.33925665]), array([0.64713127, 0.40364751]), array([0.67592312, 0.36866156]), array([13804,  6196]))\n",
      "\n",
      "\n",
      "[[170546  40255]\n",
      " [ 98297  28115]]\n",
      "(array([0.80903791, 0.22240768]), array([0.63437025, 0.41121837]), array([0.71113576, 0.28868171]), array([268843,  68370]))\n",
      "Accuracy Train:  0.5717\n",
      "Accuracy Test:  0.5891261606165836\n",
      "Step: 3\n",
      "Train Loss:  0.7541697069049241\n",
      "Test Loss:  0.7477937181944277\n",
      "[[9028 3726]\n",
      " [4863 2383]]\n",
      "(array([0.70785636, 0.3288711 ]), array([0.64991721, 0.39008021]), array([0.67765059, 0.35687009]), array([13891,  6109]))\n",
      "\n",
      "\n",
      "[[171588  40559]\n",
      " [ 97255  27811]]\n",
      "(array([0.80881653, 0.22237059]), array([0.63824611, 0.40677198]), array([0.71347845, 0.2875473 ]), array([268843,  68370]))\n",
      "Accuracy Train:  0.57055\n",
      "Accuracy Test:  0.591314688342383\n",
      "Step: 3\n",
      "Train Loss:  0.74712149179592\n",
      "Test Loss:  0.7381873818192161\n",
      "[[9119 3804]\n",
      " [4715 2362]]\n",
      "(array([0.70564111, 0.33375724]), array([0.65917305, 0.38306844]), array([0.68161603, 0.35671676]), array([13834,  6166]))\n",
      "\n",
      "\n",
      "[[174934  41448]\n",
      " [ 93909  26922]]\n",
      "(array([0.80844987, 0.22280706]), array([0.65069204, 0.3937692 ]), array([0.72104282, 0.28458623]), array([268843,  68370]))\n",
      "Accuracy Train:  0.57405\n",
      "Accuracy Test:  0.5986008843075445\n",
      "Step: 4\n",
      "Train Loss:  0.7396537177514456\n",
      "Test Loss:  0.7336329703210638\n",
      "[[9369 3688]\n",
      " [4601 2342]]\n",
      "(array([0.71754614, 0.33731816]), array([0.6706514 , 0.38839138]), array([0.69330669, 0.36105758]), array([13970,  6030]))\n",
      "\n",
      "\n",
      "[[176864  41933]\n",
      " [ 91979  26437]]\n",
      "(array([0.80834746, 0.2232553 ]), array([0.65787095, 0.38667544]), array([0.72538758, 0.28307261]), array([268843,  68370]))\n",
      "Accuracy Train:  0.58555\n",
      "Accuracy Test:  0.6028860097327209\n",
      "Step: 4\n",
      "Train Loss:  0.7346844216600266\n",
      "Test Loss:  0.7257492289684678\n",
      "[[9471 3884]\n",
      " [4401 2244]]\n",
      "(array([0.70917259, 0.33769752]), array([0.68274221, 0.36618799]), array([0.69570647, 0.35136616]), array([13872,  6128]))\n",
      "\n",
      "\n",
      "[[179846  42847]\n",
      " [ 88997  25523]]\n",
      "(array([0.80759611, 0.22286937]), array([0.66896293, 0.37330701]), array([0.73177143, 0.27910766]), array([268843,  68370]))\n",
      "Accuracy Train:  0.58575\n",
      "Accuracy Test:  0.6090186321405165\n"
     ]
    }
   ],
   "source": [
    "net = Accident_Model()\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001,weight_decay=0.95)\n",
    "criterion = nn.BCEWithLogitsLoss(weight=torch.Tensor(class_weights))\n",
    "\n",
    "for epoch in np.arange(5):\n",
    "    x_layer_pred = []\n",
    "    for batch_idx,(batch, labels) in enumerate(training_generator):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(batch).float()\n",
    "\n",
    "        loss = criterion(outputs,np.squeeze(labels))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            for test_batch, test_labels in test_generator:\n",
    "\n",
    "                test_outputs = net(test_batch)\n",
    "                #test_outputs_ = F.sigmoid(test_outputs.detach())\n",
    "                test_loss = criterion(test_outputs.float(),np.squeeze(test_labels))\n",
    "                \n",
    "                print(\"Step:\",epoch)\n",
    "                print(\"Train Loss: \", loss.item())\n",
    "                print(\"Test Loss: \", test_loss.item())\n",
    "                \n",
    "                #print(\"Error train:\",mean_absolute_error(outputs.detach().max(1).values,labels.detach().argmax(1)))\n",
    "                #print(\"Error test:\",mean_absolute_error(test_outputs.detach().max(1).values,test_labels.detach().argmax(1)))\n",
    "                \n",
    "                print(confusion_matrix(sigmoid(outputs.detach()).argmax(1), labels.detach().argmax(1)))\n",
    "                print(precision_recall_fscore_support(labels.detach().argmax(1), sigmoid(outputs.detach()).argmax(1), average=None))\n",
    "                print(\"\\n\")\n",
    "                print(confusion_matrix(sigmoid(test_outputs.detach()).argmax(1), test_labels.detach().argmax(1)))\n",
    "                print(precision_recall_fscore_support(test_labels.detach().argmax(1), sigmoid(test_outputs.detach()).argmax(1), average=None))\n",
    "                \n",
    "                \n",
    "                accuracy = accuracy_score(labels.detach().argmax(1), sigmoid(outputs.detach()).argmax(1))\n",
    "                print(\"Accuracy Train: \", accuracy)\n",
    "                accuracy = accuracy_score(test_labels.detach().argmax(1), sigmoid(test_outputs.detach()).argmax(1))\n",
    "                print(\"Accuracy Test: \", accuracy)\n",
    "                break;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_layer_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.796704</td>\n",
       "      <td>-0.054295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.822240</td>\n",
       "      <td>0.308871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.598832</td>\n",
       "      <td>-0.856095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.523629</td>\n",
       "      <td>-0.917408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.352438</td>\n",
       "      <td>-1.026290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034905</th>\n",
       "      <td>-0.363081</td>\n",
       "      <td>-0.960096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034906</th>\n",
       "      <td>-0.363081</td>\n",
       "      <td>-0.960096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034907</th>\n",
       "      <td>-0.126688</td>\n",
       "      <td>-0.928808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034908</th>\n",
       "      <td>-0.628960</td>\n",
       "      <td>-0.995287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034909</th>\n",
       "      <td>-0.543370</td>\n",
       "      <td>-0.983959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3034910 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1\n",
       "0        0.796704 -0.054295\n",
       "1        0.822240  0.308871\n",
       "2       -1.598832 -0.856095\n",
       "3       -1.523629 -0.917408\n",
       "4       -1.352438 -1.026290\n",
       "...           ...       ...\n",
       "3034905 -0.363081 -0.960096\n",
       "3034906 -0.363081 -0.960096\n",
       "3034907 -0.126688 -0.928808\n",
       "3034908 -0.628960 -0.995287\n",
       "3034909 -0.543370 -0.983959\n",
       "\n",
       "[3034910 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = pd.DataFrame(net(torch.Tensor(all_data.iloc[:train_frac,:8].values)).detach().numpy())\n",
    "test_pred = pd.DataFrame(net(torch.Tensor(all_data.iloc[train_frac:,:8].values)).detach().numpy())\n",
    "train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_pred.loc[np.where(all_data.iloc[:train_frac,8].values == 3)[0]]\n",
    "len(x_layer_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42,sampling_strategy='minority')\n",
    "X_res, y_res = sm.fit_resample(x_layer_pred[154].detach().numpy(), all_data.iloc[:train_frac,8].values - 2)\n",
    "X_res_test, y_res_test = sm.fit_resample(x_layer_pred[155].detach().numpy(), all_data.iloc[train_frac:,8].values - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:21:52] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_dist = {'n_estimators':150, 'max_depth':4}\n",
    "\n",
    "xgboost_model = XGBClassifier(**param_dist)\n",
    "xgboost_model.fit(X_res, y_res, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error Train: 0.4880507164957116\n",
      "Accuracy:  0.5119492835042885\n",
      "(array([0.73780934, 0.34036117]), array([0.45938327, 0.63082415]), array([0.56622012, 0.4421567 ]), array([2104367,  930543]))\n",
      "Mean Absolute Error Test : 0.6705939569352308\n",
      "Accuracy:  0.32940604306476917\n",
      "(array([0.81622982, 0.20750288]), array([0.20502673, 0.81848764]), array([0.32773142, 0.33107235]), array([268843,  68370]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "x_train_xgboost = xgboost_model.predict(x_layer_pred[154].detach().numpy())\n",
    "print(\"Mean Absolute Error Train: \" + str(mean_absolute_error(x_train_xgboost, all_data.iloc[:train_frac,8].values - 2)))\n",
    "accuracy = accuracy_score(all_data.iloc[:train_frac,8].values - 2, np.round(x_train_xgboost))\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(precision_recall_fscore_support(all_data.iloc[:train_frac,8].values - 2, np.round(x_train_xgboost)))\n",
    "\n",
    "\n",
    "# make predictions\n",
    "x_test_xgboost = xgboost_model.predict(x_layer_pred[155].detach().numpy())\n",
    "print(\"Mean Absolute Error Test : \" + str(mean_absolute_error(x_test_xgboost, all_data.iloc[train_frac:,8].values - 2)))\n",
    "accuracy = accuracy_score(all_data.iloc[train_frac:,8].values - 2, np.round(x_test_xgboost))\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(precision_recall_fscore_support(all_data.iloc[train_frac:,8].values - 2, np.round(x_test_xgboost)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
